# News-Analyzer-using-vectorization

Project Overview
The News Authenticity Analyzer is a machine learning-based tool designed to assess the authenticity of news articles. It leverages various text preprocessing techniques and multiple classification algorithms to provide a confidence score indicating the likelihood that a given news article is genuine or fake.

Project Structure
The project consists of the following key components:

Abstract

A brief overview of the project, highlighting the importance of detecting fake news and the approach taken in this project.
Introduction

Detailed background information on the digital media landscape and the challenges posed by the spread of false information.
Objective

Specific goals of the project, including data compilation, feature selection, algorithm development, model testing and evaluation, and community impact.
Dataset

Information on the dataset used, sourced from Kaggle's "Fake News Detection" dataset, which includes headlines, full-text articles, and labels indicating whether the news is real or fake.
Preprocessing

Techniques used to preprocess the text data, including stemming, lemmatizing, sentiment analysis, and vectorization using Doc2Vec.
Classification Models

Various machine learning models employed for classification, such as Naive Bayes, Support Vector Machine, Decision Tree, K-Nearest Neighbors, Logistic Regression, Gradient Boosting, and neural networks.
Metrics

Metrics used to evaluate the performance of the models, including accuracy, Cohen's Kappa Score, Matthews Correlation Coefficient (MCC), and binary cross-entropy.
Results

Performance results of the different models, highlighting their accuracy and other relevant metrics.
Conclusion

Summary of findings, emphasizing the balance between accuracy and generalization in model performance, and the potential of ensemble techniques.
